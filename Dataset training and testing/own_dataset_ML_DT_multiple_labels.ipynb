{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b3d806-4ff7-4a58-822a-487ec28c0072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df = pd.read_csv('research_traffic_multiple_labels.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d5044e-30e4-4889-b8b5-cf9446f8051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Source IP        int64\n",
      "Port Count                int64\n",
      "Pair Count Ratio        float64\n",
      "Packet Count Diff         int64\n",
      "Lookup Count Diff         int64\n",
      "Protocol                  int64\n",
      "Average Packet Count    float64\n",
      "Average Byte Count      float64\n",
      "Packet Std Dev          float64\n",
      "Byte Std Dev            float64\n",
      "Duration per Flow       float64\n",
      "Label                     int64\n",
      "dtype: object\n",
      "10000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count of Source IP</th>\n",
       "      <th>Port Count</th>\n",
       "      <th>Pair Count Ratio</th>\n",
       "      <th>Packet Count Diff</th>\n",
       "      <th>Lookup Count Diff</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Average Packet Count</th>\n",
       "      <th>Average Byte Count</th>\n",
       "      <th>Packet Std Dev</th>\n",
       "      <th>Byte Std Dev</th>\n",
       "      <th>Duration per Flow</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>4.788991</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>28.466647</td>\n",
       "      <td>0.668020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>1.596330</td>\n",
       "      <td>0.095342</td>\n",
       "      <td>16.589551</td>\n",
       "      <td>0.419081</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>4.150459</td>\n",
       "      <td>0.355016</td>\n",
       "      <td>61.772825</td>\n",
       "      <td>2.946281</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>4.788991</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>28.466647</td>\n",
       "      <td>2.674461</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count of Source IP  Port Count  Pair Count Ratio  Packet Count Diff  \\\n",
       "0                 545         545               0.0                  2   \n",
       "1                 545         545               0.0                 10   \n",
       "2                  52          52               0.0                  3   \n",
       "3                 545         545               0.0                 13   \n",
       "4                 545         545               0.0                  2   \n",
       "\n",
       "   Lookup Count Diff  Protocol  Average Packet Count  Average Byte Count  \\\n",
       "0                 43         6              0.027523            4.788991   \n",
       "1                  0         6              0.009174            1.596330   \n",
       "2                  0         6              0.000000            0.000000   \n",
       "3                 21         6              0.023853            4.150459   \n",
       "4                131         6              0.027523            4.788991   \n",
       "\n",
       "   Packet Std Dev  Byte Std Dev  Duration per Flow  Label  \n",
       "0        0.163601     28.466647           0.668020      3  \n",
       "1        0.095342     16.589551           0.419081      3  \n",
       "2        0.000000      0.000000           0.018792      3  \n",
       "3        0.355016     61.772825           2.946281      3  \n",
       "4        0.163601     28.466647           2.674461      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dt = df\n",
    "print(df_dt.dtypes)\n",
    "print(df_dt['Label'].value_counts()[1])\n",
    "print(df_dt['Label'].value_counts()[0])\n",
    "df_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb6bce6-e849-43c6-b3c9-d456368ac9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obj_cols=df_dt.dtypes[df_dt.dtypes == \"object\"].index.values.tolist()\n",
    "# print(obj_cols)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# #Encode labels of multiple columns at once\n",
    "\n",
    "# df_dt[obj_cols] = df_dt[obj_cols].astype(str)\n",
    "# df_dt[obj_cols] = df_dt[obj_cols].apply(LabelEncoder().fit_transform)\n",
    "# #\n",
    "# # Print head\n",
    "# #\n",
    "# print(df_dt.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa701bd-bb1b-4e89-86c2-3c623d9b981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset normalized using MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score, make_scorer\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "y = df.Label\n",
    "X = df.drop(['Label'],axis=1)\n",
    "\n",
    "# Normalize the dataset using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "X = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "print(\"Dataset normalized using MinMaxScaler.\")\n",
    "\n",
    "# # Scale the dataset using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "X_train_cv, X_unseen_test, y_train_cv, y_unseen_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c760dda-b4ee-4dd7-90ba-dd0518bafd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "start = datetime.now()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_cv):\n",
    "    X_train, X_test = X_train_cv.iloc[train_index], X_train_cv.iloc[test_index]\n",
    "    y_train, y_test = y_train_cv.iloc[train_index], y_train_cv.iloc[test_index]\n",
    "    \n",
    "    # Train the dt classifier\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test fold\n",
    "    y_pred_test = dt.predict(X_test)\n",
    "    y_pred_train = dt.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics for the test fold\n",
    "    train_accuracies.append(accuracy_score(y_train, y_pred_train))\n",
    "    test_accuracies.append(accuracy_score(y_test, y_pred_test))\n",
    "    precisions.append(precision_score(y_test, y_pred_test, average='weighted'))\n",
    "    recalls.append(recall_score(y_test, y_pred_test, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
    "    \n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Test the final model on unseen data\n",
    "y_unseen_pred = dt.predict(X_unseen_test)\n",
    "unseen_accuracy = accuracy_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_precision = precision_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_recall = recall_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_f1 = f1_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_conf_matrix = confusion_matrix(y_unseen_test, y_unseen_pred)\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2dfa226-4a1a-486e-9d92-78f390c177ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix:\n",
      "632.40  36.40   0.60  34.10   1.10  94.50\n",
      " 35.50 747.90   0.50   0.00   0.10  10.40\n",
      "  1.10   0.30 797.90   0.00   0.00   0.20\n",
      " 32.90   0.00   0.10 766.40   0.00   0.20\n",
      "  1.30   0.10   0.00   0.00 802.00   0.10\n",
      " 96.10   9.00   0.50   0.20   0.00 698.10\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average confusion matrix for multi-class classification\n",
    "import numpy as np\n",
    "\n",
    "# Determine the number of classes from the confusion matrices\n",
    "num_classes = confusion_matrices[0].shape[0]\n",
    "\n",
    "# Initialize an array to store the sum of confusion matrices\n",
    "confusion_matrix_sum = np.zeros((num_classes, num_classes))\n",
    "\n",
    "# Sum up the confusion matrices from all folds\n",
    "for cm in confusion_matrices:\n",
    "    confusion_matrix_sum += cm\n",
    "\n",
    "# Compute the average confusion matrix\n",
    "average_conf_matrix = confusion_matrix_sum / len(confusion_matrices)\n",
    "\n",
    "# Display the average confusion matrix\n",
    "print(\"Average Confusion Matrix:\")\n",
    "max_width = max(len(\"{:.2f}\".format(value)) for row in average_conf_matrix for value in row)\n",
    "\n",
    "# Print each row with formatted values\n",
    "for row in average_conf_matrix:\n",
    "    print(\" \".join(f\"{value:>{max_width}.2f}\" for value in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c29e3b50-cb72-4f68-9fa7-a0679b9cfcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9235416666666667\n",
      "Precision: 0.9237726631951418\n",
      "Recall: 0.9235416666666667\n",
      "F1-Score: 0.9236517418850783\n",
      "Confusion Matrix:\n",
      "[[590  44   0  28   2  97]\n",
      " [ 44 768   0   0   0   8]\n",
      " [  1   0 772   0   0   0]\n",
      " [ 29   0   0 765   0   0]\n",
      " [  3   0   0   0 804   0]\n",
      " [102   8   0   1   0 734]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.9999768518518518\n",
      "Testing Accuracy: 0.92\n",
      "Precision: 0.9201637873782123\n",
      "Recall: 0.92\n",
      "F1-Score: 0.920071017918586\n",
      "Confusion Matrix:\n",
      "[[650  32   0  41   3 103]\n",
      " [ 35 726   1   0   0  15]\n",
      " [  0   1 811   0   0   0]\n",
      " [ 43   0   0 771   0   0]\n",
      " [  0   0   0   0 785   0]\n",
      " [102   8   0   0   0 673]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9999537037037037\n",
      "Testing Accuracy: 0.924375\n",
      "Precision: 0.9246215161510063\n",
      "Recall: 0.924375\n",
      "F1-Score: 0.9244777656084813\n",
      "Confusion Matrix:\n",
      "[[622  34   1  32   1 100]\n",
      " [ 39 794   1   0   0  13]\n",
      " [  0   0 773   0   0   1]\n",
      " [ 39   0   0 785   0   1]\n",
      " [  1   0   0   0 768   0]\n",
      " [ 88  11   1   0   0 695]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.9999537037037037\n",
      "Testing Accuracy: 0.9277083333333334\n",
      "Precision: 0.9270765285864475\n",
      "Recall: 0.9277083333333334\n",
      "F1-Score: 0.9273449394656499\n",
      "Confusion Matrix:\n",
      "[[648  38   0  42   2  93]\n",
      " [ 35 718   1   0   0   5]\n",
      " [  2   1 838   0   0   0]\n",
      " [ 25   0   0 747   0   0]\n",
      " [  1   0   0   0 802   0]\n",
      " [ 91  11   0   0   0 700]]\n",
      "\n",
      "Fold 5:\n",
      "Training Accuracy: 0.9999537037037037\n",
      "Testing Accuracy: 0.9285416666666667\n",
      "Precision: 0.9283699492624748\n",
      "Recall: 0.9285416666666667\n",
      "F1-Score: 0.9284318540166523\n",
      "Confusion Matrix:\n",
      "[[644  43   2  29   0  95]\n",
      " [ 23 761   0   0   1  10]\n",
      " [  2   0 790   0   0   0]\n",
      " [ 39   0   0 753   0   0]\n",
      " [  0   0   0   0 795   0]\n",
      " [ 95   4   0   0   0 714]]\n",
      "\n",
      "Fold 6:\n",
      "Training Accuracy: 0.9999768518518518\n",
      "Testing Accuracy: 0.9260416666666667\n",
      "Precision: 0.9261923370813042\n",
      "Recall: 0.9260416666666667\n",
      "F1-Score: 0.9261107378602499\n",
      "Confusion Matrix:\n",
      "[[626  44   1  33   0  87]\n",
      " [ 40 740   0   0   0   9]\n",
      " [  3   0 786   0   0   0]\n",
      " [ 31   0   0 782   0   1]\n",
      " [  2   0   0   0 827   0]\n",
      " [ 95   9   0   0   0 684]]\n",
      "\n",
      "Fold 7:\n",
      "Training Accuracy: 0.9999537037037037\n",
      "Testing Accuracy: 0.924375\n",
      "Precision: 0.9250803705869614\n",
      "Recall: 0.924375\n",
      "F1-Score: 0.9246653501428924\n",
      "Confusion Matrix:\n",
      "[[624  30   0  29   1  93]\n",
      " [ 34 739   0   0   0  16]\n",
      " [  0   0 813   0   0   0]\n",
      " [ 33   0   0 768   0   0]\n",
      " [  1   0   0   0 795   0]\n",
      " [113  11   2   0   0 698]]\n",
      "\n",
      "Fold 8:\n",
      "Training Accuracy: 0.9999537037037037\n",
      "Testing Accuracy: 0.9316666666666666\n",
      "Precision: 0.9312670949294319\n",
      "Recall: 0.9316666666666666\n",
      "F1-Score: 0.9314294721741383\n",
      "Confusion Matrix:\n",
      "[[645  38   0  43   0  79]\n",
      " [ 30 738   1   0   0  11]\n",
      " [  2   0 807   0   0   1]\n",
      " [ 24   0   0 773   0   0]\n",
      " [  2   0   0   0 806   1]\n",
      " [ 87   9   0   0   0 703]]\n",
      "\n",
      "Fold 9:\n",
      "Training Accuracy: 0.9999537037037037\n",
      "Testing Accuracy: 0.9297916666666667\n",
      "Precision: 0.9301464470974522\n",
      "Recall: 0.9297916666666667\n",
      "F1-Score: 0.9299454569626645\n",
      "Confusion Matrix:\n",
      "[[651  27   0  29   0  90]\n",
      " [ 34 764   1   0   0  11]\n",
      " [  0   1 776   0   0   0]\n",
      " [ 31   0   0 771   0   0]\n",
      " [  1   0   0   0 815   0]\n",
      " [ 97  13   1   1   0 686]]\n",
      "\n",
      "Fold 10:\n",
      "Training Accuracy: 0.9999537037037037\n",
      "Testing Accuracy: 0.92375\n",
      "Precision: 0.9236565062391259\n",
      "Recall: 0.92375\n",
      "F1-Score: 0.923679753883733\n",
      "Confusion Matrix:\n",
      "[[624  34   2  35   2 108]\n",
      " [ 41 731   0   0   0   6]\n",
      " [  1   0 813   0   0   0]\n",
      " [ 35   0   1 749   0   0]\n",
      " [  2   1   0   0 823   0]\n",
      " [ 91   6   1   0   0 694]]\n",
      "\n",
      "Average Training Accuracy: 0.9999629629629629\n",
      "Average Testing Accuracy: 0.9259791666666667\n",
      "Average Precision: 0.926034720050756\n",
      "Average recall: 0.9259791666666667\n",
      "Average F1 Score: 0.9259808089918126\n",
      "Performance on Unseen Data:\n",
      "Accuracy: 0.9224166666666667\n",
      "Precision: 0.9224408102778786\n",
      "Recall: 0.9224166666666667\n",
      "F1-Score: 0.9224207225671108\n",
      "Confusion Matrix:\n",
      "[[1567   86    6   86    5  259]\n",
      " [  94 1935    0    0    0   27]\n",
      " [   2    2 2000    1    0    0]\n",
      " [  97    0    0 1907    0    0]\n",
      " [   3    2    0    0 1960    0]\n",
      " [ 234   25    1    1    0 1700]]\n",
      "excution time:  0:00:02.252112\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics for each fold\n",
    "for i in range(10):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[i]}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1-Score: {f1_scores[i]}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrices[i]}\\n\")\n",
    "\n",
    "print(f\"Average Training Accuracy: {sum(train_accuracies) / 10}\")\n",
    "print(f\"Average Testing Accuracy: {sum(test_accuracies) / 10}\")\n",
    "print(f\"Average Precision: {sum(precisions) / 10}\")\n",
    "print(f\"Average recall: {sum(recalls) / 10}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / 10}\")\n",
    "\n",
    "# Print the performance on the unseen data\n",
    "print(\"Performance on Unseen Data:\")\n",
    "print(f\"Accuracy: {unseen_accuracy}\")\n",
    "print(f\"Precision: {unseen_precision}\")\n",
    "print(f\"Recall: {unseen_recall}\")\n",
    "print(f\"F1-Score: {unseen_f1}\")\n",
    "print(f\"Confusion Matrix:\\n{unseen_conf_matrix}\")\n",
    "print(\"excution time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605dcc42-926e-43fa-9fcc-8a878e042bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted Feature Importance (WFI):\n",
      "                 Feature  Importance\n",
      "0     Count of Source IP    0.334316\n",
      "1             Port Count    0.232295\n",
      "5               Protocol    0.180745\n",
      "6   Average Packet Count    0.141760\n",
      "10     Duration per Flow    0.063430\n",
      "4      Lookup Count Diff    0.019902\n",
      "3      Packet Count Diff    0.019150\n",
      "8         Packet Std Dev    0.005457\n",
      "2       Pair Count Ratio    0.001861\n",
      "9           Byte Std Dev    0.001024\n",
      "7     Average Byte Count    0.000060\n"
     ]
    }
   ],
   "source": [
    "# Calculate Weighted Feature Importance (WFI)\n",
    "feature_importances = dt.feature_importances_\n",
    "wfi = feature_importances / feature_importances.sum()\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': wfi\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nWeighted Feature Importance (WFI):\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8b2ecef-358e-4bdd-8d22-c900d5227704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('dt_multi.pkl', 'wb') as file:\n",
    "#     pickle.dump(dt, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
