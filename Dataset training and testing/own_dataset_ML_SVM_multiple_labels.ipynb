{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b5b3af-63d8-42c3-a890-6514a5da4feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df = pd.read_csv('research_traffic_multiple_labels.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33caf8a8-1b83-4994-80c5-70435133916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Source IP        int64\n",
      "Port Count                int64\n",
      "Pair Count Ratio        float64\n",
      "Packet Count Diff         int64\n",
      "Lookup Count Diff         int64\n",
      "Protocol                  int64\n",
      "Average Packet Count    float64\n",
      "Average Byte Count      float64\n",
      "Packet Std Dev          float64\n",
      "Byte Std Dev            float64\n",
      "Duration per Flow       float64\n",
      "Label                     int64\n",
      "dtype: object\n",
      "10000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count of Source IP</th>\n",
       "      <th>Port Count</th>\n",
       "      <th>Pair Count Ratio</th>\n",
       "      <th>Packet Count Diff</th>\n",
       "      <th>Lookup Count Diff</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Average Packet Count</th>\n",
       "      <th>Average Byte Count</th>\n",
       "      <th>Packet Std Dev</th>\n",
       "      <th>Byte Std Dev</th>\n",
       "      <th>Duration per Flow</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>4.788991</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>28.466647</td>\n",
       "      <td>0.668020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>1.596330</td>\n",
       "      <td>0.095342</td>\n",
       "      <td>16.589551</td>\n",
       "      <td>0.419081</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>4.150459</td>\n",
       "      <td>0.355016</td>\n",
       "      <td>61.772825</td>\n",
       "      <td>2.946281</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>4.788991</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>28.466647</td>\n",
       "      <td>2.674461</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count of Source IP  Port Count  Pair Count Ratio  Packet Count Diff  \\\n",
       "0                 545         545               0.0                  2   \n",
       "1                 545         545               0.0                 10   \n",
       "2                  52          52               0.0                  3   \n",
       "3                 545         545               0.0                 13   \n",
       "4                 545         545               0.0                  2   \n",
       "\n",
       "   Lookup Count Diff  Protocol  Average Packet Count  Average Byte Count  \\\n",
       "0                 43         6              0.027523            4.788991   \n",
       "1                  0         6              0.009174            1.596330   \n",
       "2                  0         6              0.000000            0.000000   \n",
       "3                 21         6              0.023853            4.150459   \n",
       "4                131         6              0.027523            4.788991   \n",
       "\n",
       "   Packet Std Dev  Byte Std Dev  Duration per Flow  Label  \n",
       "0        0.163601     28.466647           0.668020      3  \n",
       "1        0.095342     16.589551           0.419081      3  \n",
       "2        0.000000      0.000000           0.018792      3  \n",
       "3        0.355016     61.772825           2.946281      3  \n",
       "4        0.163601     28.466647           2.674461      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df['Label'].value_counts()[1])\n",
    "print(df['Label'].value_counts()[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410313ce-53c1-4b71-8595-654effb65089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_cols=df.dtypes[df.dtypes == \"object\"].index.values.tolist()\n",
    "# print(obj_cols)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# #Encode labels of multiple columns at once\n",
    "\n",
    "# df[obj_cols] = df[obj_cols].astype(str)\n",
    "# df[obj_cols] = df[obj_cols].apply(LabelEncoder().fit_transform)\n",
    "# #\n",
    "# # Print head\n",
    "# #\n",
    "# print(df.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82de71f3-1029-4e47-afc5-5c014ca6a3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset normalized using MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "y = df.Label\n",
    "X = df.drop(['Label'],axis=1)\n",
    "\n",
    "# Normalize the dataset using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "X = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "print(\"Dataset normalized using MinMaxScaler.\")\n",
    "\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "X_train_cv, X_unseen_test, y_train_cv, y_unseen_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514d448d-b2c2-40f8-bf41-de591c275ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "start = datetime.now()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_cv):\n",
    "    X_train, X_test = X_train_cv.iloc[train_index], X_train_cv.iloc[test_index]\n",
    "    y_train, y_test = y_train_cv.iloc[train_index], y_train_cv.iloc[test_index]\n",
    "    \n",
    "    # Train the SVM classifier\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test fold\n",
    "    y_pred_test = svm_model.predict(X_test)\n",
    "    y_pred_train = svm_model.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics for the test fold\n",
    "    train_accuracies.append(accuracy_score(y_train, y_pred_train))\n",
    "    test_accuracies.append(accuracy_score(y_test, y_pred_test))\n",
    "    precisions.append(precision_score(y_test, y_pred_test, average='weighted'))\n",
    "    recalls.append(recall_score(y_test, y_pred_test, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Test the final model on unseen data\n",
    "y_unseen_pred = svm_model.predict(X_unseen_test)\n",
    "unseen_accuracy = accuracy_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_precision = precision_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_recall = recall_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_f1 = f1_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_conf_matrix = confusion_matrix(y_unseen_test, y_unseen_pred)\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4950b78-1322-4bc5-b2c5-c1c2bc9c4299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix:\n",
      "528.60  35.40   0.10  47.70   9.50 177.80\n",
      " 17.60 745.10   0.00   0.00   3.40  28.30\n",
      "  8.30   0.00 790.50   0.00   0.70   0.00\n",
      "  1.70   0.00   0.00 793.40   0.00   4.50\n",
      "  4.00   0.00   0.00   0.00 799.50   0.00\n",
      "  6.50   0.00   0.00   0.00   0.30 797.10\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average confusion matrix for multi-class classification\n",
    "import numpy as np\n",
    "\n",
    "# Determine the number of classes from the confusion matrices\n",
    "num_classes = confusion_matrices[0].shape[0]\n",
    "\n",
    "# Initialize an array to store the sum of confusion matrices\n",
    "confusion_matrix_sum = np.zeros((num_classes, num_classes))\n",
    "\n",
    "# Sum up the confusion matrices from all folds\n",
    "for cm in confusion_matrices:\n",
    "    confusion_matrix_sum += cm\n",
    "\n",
    "# Compute the average confusion matrix\n",
    "average_conf_matrix = confusion_matrix_sum / len(confusion_matrices)\n",
    "\n",
    "# Display the average confusion matrix\n",
    "print(\"Average Confusion Matrix:\")\n",
    "max_width = max(len(\"{:.2f}\".format(value)) for row in average_conf_matrix for value in row)\n",
    "\n",
    "# Print each row with formatted values\n",
    "for row in average_conf_matrix:\n",
    "    print(\" \".join(f\"{value:>{max_width}.2f}\" for value in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a39de8-2b02-4857-8bbf-878379326529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training Accuracy: 0.927962962962963\n",
      "Testing Accuracy: 0.9308333333333333\n",
      "Precision: 0.9364463043263026\n",
      "Recall: 0.9308333333333333\n",
      "F1-Score: 0.92772201904099\n",
      "Confusion Matrix:\n",
      "[[496  42   1  37   9 176]\n",
      " [ 17 773   0   0   0  30]\n",
      " [  7   0 766   0   0   0]\n",
      " [  1   0   0 790   0   3]\n",
      " [  3   0   0   0 804   0]\n",
      " [  6   0   0   0   0 839]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.928587962962963\n",
      "Testing Accuracy: 0.9214583333333334\n",
      "Precision: 0.9286010541884343\n",
      "Recall: 0.9214583333333334\n",
      "F1-Score: 0.9183287006161586\n",
      "Confusion Matrix:\n",
      "[[535  31   0  59   9 195]\n",
      " [ 23 720   0   0   4  30]\n",
      " [ 10   0 802   0   0   0]\n",
      " [  2   0   0 808   0   4]\n",
      " [  5   0   0   0 780   0]\n",
      " [  5   0   0   0   0 778]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9281018518518519\n",
      "Testing Accuracy: 0.928125\n",
      "Precision: 0.9351240955260735\n",
      "Recall: 0.928125\n",
      "F1-Score: 0.9254375545878598\n",
      "Confusion Matrix:\n",
      "[[520  33   0  43  11 183]\n",
      " [ 14 801   0   0   1  31]\n",
      " [ 11   0 762   0   1   0]\n",
      " [  2   0   0 816   0   7]\n",
      " [  2   0   0   0 767   0]\n",
      " [  6   0   0   0   0 789]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.9283333333333333\n",
      "Testing Accuracy: 0.9266666666666666\n",
      "Precision: 0.9323250474129717\n",
      "Recall: 0.9266666666666666\n",
      "F1-Score: 0.9234942869845326\n",
      "Confusion Matrix:\n",
      "[[544  38   0  58  11 172]\n",
      " [ 17 710   0   0   6  26]\n",
      " [  5   0 835   0   1   0]\n",
      " [  1   0   0 768   0   3]\n",
      " [  4   0   0   0 799   0]\n",
      " [  9   0   0   0   1 792]]\n",
      "\n",
      "Fold 5:\n",
      "Training Accuracy: 0.9278472222222223\n",
      "Testing Accuracy: 0.9289583333333333\n",
      "Precision: 0.9355569173532455\n",
      "Recall: 0.9289583333333333\n",
      "F1-Score: 0.9263161172584311\n",
      "Confusion Matrix:\n",
      "[[544  42   0  36  10 181]\n",
      " [ 11 751   0   0   4  29]\n",
      " [  9   0 782   0   1   0]\n",
      " [  2   0   0 785   0   5]\n",
      " [  4   0   0   0 791   0]\n",
      " [  7   0   0   0   0 806]]\n",
      "\n",
      "Fold 6:\n",
      "Training Accuracy: 0.927962962962963\n",
      "Testing Accuracy: 0.9277083333333334\n",
      "Precision: 0.93257280806787\n",
      "Recall: 0.9277083333333334\n",
      "F1-Score: 0.9248765111316629\n",
      "Confusion Matrix:\n",
      "[[526  39   0  53   8 165]\n",
      " [ 23 738   0   0   5  23]\n",
      " [  8   0 781   0   0   0]\n",
      " [  2   0   0 803   0   9]\n",
      " [  7   0   0   0 822   0]\n",
      " [  5   0   0   0   0 783]]\n",
      "\n",
      "Fold 7:\n",
      "Training Accuracy: 0.9279398148148148\n",
      "Testing Accuracy: 0.9285416666666667\n",
      "Precision: 0.9344429430583638\n",
      "Recall: 0.9285416666666667\n",
      "F1-Score: 0.925535352657194\n",
      "Confusion Matrix:\n",
      "[[508  33   0  47  11 178]\n",
      " [ 15 741   0   0   2  31]\n",
      " [  7   0 805   0   1   0]\n",
      " [  2   0   0 796   0   3]\n",
      " [  6   0   0   0 790   0]\n",
      " [  7   0   0   0   0 817]]\n",
      "\n",
      "Fold 8:\n",
      "Training Accuracy: 0.9275925925925926\n",
      "Testing Accuracy: 0.9308333333333333\n",
      "Precision: 0.9355229195300095\n",
      "Recall: 0.9308333333333333\n",
      "F1-Score: 0.9284183209845528\n",
      "Confusion Matrix:\n",
      "[[554  37   0  54   8 152]\n",
      " [ 17 727   0   0   3  33]\n",
      " [  9   0 800   0   1   0]\n",
      " [  3   0   0 791   0   3]\n",
      " [  2   0   0   0 807   0]\n",
      " [  9   0   0   0   1 789]]\n",
      "\n",
      "Fold 9:\n",
      "Training Accuracy: 0.9273611111111111\n",
      "Testing Accuracy: 0.93375\n",
      "Precision: 0.93975457832341\n",
      "Recall: 0.93375\n",
      "F1-Score: 0.9316330550262971\n",
      "Confusion Matrix:\n",
      "[[550  28   0  37  10 172]\n",
      " [ 18 759   0   0   4  29]\n",
      " [  7   0 770   0   0   0]\n",
      " [  2   0   0 797   0   3]\n",
      " [  3   0   0   0 813   0]\n",
      " [  5   0   0   0   0 793]]\n",
      "\n",
      "Fold 10:\n",
      "Training Accuracy: 0.9284722222222223\n",
      "Testing Accuracy: 0.9227083333333334\n",
      "Precision: 0.9298239893154007\n",
      "Recall: 0.9227083333333334\n",
      "F1-Score: 0.9192492328695098\n",
      "Confusion Matrix:\n",
      "[[509  31   0  53   8 204]\n",
      " [ 21 731   0   0   5  21]\n",
      " [ 10   0 802   0   2   0]\n",
      " [  0   0   0 780   0   5]\n",
      " [  4   0   0   0 822   0]\n",
      " [  6   0   0   0   1 785]]\n",
      "\n",
      "Average Training Accuracy: 0.9280162037037037\n",
      "Average Testing Accuracy: 0.9279583333333333\n",
      "Average Precision: 0.934017065710208\n",
      "Average recall: 0.9279583333333333\n",
      "Average F1 Score: 0.9251011151157188\n",
      "Performance on Unseen Data:\n",
      "Accuracy: 0.9264166666666667\n",
      "Precision: 0.9324266492895448\n",
      "Recall: 0.9264166666666667\n",
      "F1-Score: 0.9236319936006778\n",
      "Confusion Matrix:\n",
      "[[1329   93    0  118   24  445]\n",
      " [  54 1914    0    0   11   77]\n",
      " [  17    0 1988    0    0    0]\n",
      " [   5    0    0 1990    0    9]\n",
      " [  15    0    0    0 1950    0]\n",
      " [  15    0    0    0    0 1946]]\n",
      "excution time:  0:07:11.181427\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics for each fold\n",
    "for i in range(10):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[i]}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1-Score: {f1_scores[i]}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrices[i]}\\n\")\n",
    "\n",
    "print(f\"Average Training Accuracy: {sum(train_accuracies) / 10}\")\n",
    "print(f\"Average Testing Accuracy: {sum(test_accuracies) / 10}\")\n",
    "print(f\"Average Precision: {sum(precisions) / 10}\")\n",
    "print(f\"Average recall: {sum(recalls) / 10}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / 10}\")\n",
    "\n",
    "# Print the performance on the unseen data\n",
    "print(\"Performance on Unseen Data:\")\n",
    "print(f\"Accuracy: {unseen_accuracy}\")\n",
    "print(f\"Precision: {unseen_precision}\")\n",
    "print(f\"Recall: {unseen_recall}\")\n",
    "print(f\"F1-Score: {unseen_f1}\")\n",
    "print(f\"Confusion Matrix:\\n{unseen_conf_matrix}\")\n",
    "print(\"excution time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0297cb5a-c07a-4247-952d-91fc6722a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('svm_multi.pkl', 'wb') as file:\n",
    "#     pickle.dump(svm_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
