{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be54130f-a0b8-4cea-a078-8a1334c56b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df = pd.read_csv('research_traffic_multiple_labels.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2eaa4d-725c-42a9-9509-b93a9a697fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Source IP        int64\n",
      "Port Count                int64\n",
      "Pair Count Ratio        float64\n",
      "Packet Count Diff         int64\n",
      "Lookup Count Diff         int64\n",
      "Protocol                  int64\n",
      "Average Packet Count    float64\n",
      "Average Byte Count      float64\n",
      "Packet Std Dev          float64\n",
      "Byte Std Dev            float64\n",
      "Duration per Flow       float64\n",
      "Label                     int64\n",
      "dtype: object\n",
      "10000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count of Source IP</th>\n",
       "      <th>Port Count</th>\n",
       "      <th>Pair Count Ratio</th>\n",
       "      <th>Packet Count Diff</th>\n",
       "      <th>Lookup Count Diff</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Average Packet Count</th>\n",
       "      <th>Average Byte Count</th>\n",
       "      <th>Packet Std Dev</th>\n",
       "      <th>Byte Std Dev</th>\n",
       "      <th>Duration per Flow</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>4.788991</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>28.466647</td>\n",
       "      <td>0.668020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>1.596330</td>\n",
       "      <td>0.095342</td>\n",
       "      <td>16.589551</td>\n",
       "      <td>0.419081</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>4.150459</td>\n",
       "      <td>0.355016</td>\n",
       "      <td>61.772825</td>\n",
       "      <td>2.946281</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>4.788991</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>28.466647</td>\n",
       "      <td>2.674461</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count of Source IP  Port Count  Pair Count Ratio  Packet Count Diff  \\\n",
       "0                 545         545               0.0                  2   \n",
       "1                 545         545               0.0                 10   \n",
       "2                  52          52               0.0                  3   \n",
       "3                 545         545               0.0                 13   \n",
       "4                 545         545               0.0                  2   \n",
       "\n",
       "   Lookup Count Diff  Protocol  Average Packet Count  Average Byte Count  \\\n",
       "0                 43         6              0.027523            4.788991   \n",
       "1                  0         6              0.009174            1.596330   \n",
       "2                  0         6              0.000000            0.000000   \n",
       "3                 21         6              0.023853            4.150459   \n",
       "4                131         6              0.027523            4.788991   \n",
       "\n",
       "   Packet Std Dev  Byte Std Dev  Duration per Flow  Label  \n",
       "0        0.163601     28.466647           0.668020      3  \n",
       "1        0.095342     16.589551           0.419081      3  \n",
       "2        0.000000      0.000000           0.018792      3  \n",
       "3        0.355016     61.772825           2.946281      3  \n",
       "4        0.163601     28.466647           2.674461      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df['Label'].value_counts()[1])\n",
    "print(df['Label'].value_counts()[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6623849d-3cb4-4315-b7f6-94666c3533d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_cols=df.dtypes[df.dtypes == \"object\"].index.values.tolist()\n",
    "# print(obj_cols)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# #Encode labels of multiple columns at once\n",
    "\n",
    "# df[obj_cols] = df[obj_cols].astype(str)\n",
    "# df[obj_cols] = df[obj_cols].apply(LabelEncoder().fit_transform)\n",
    "# #\n",
    "# # Print head\n",
    "# #\n",
    "# print(df.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566a0563-73e8-491c-a979-7132ecfd14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset normalized using MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "y = df.Label\n",
    "X = df.drop(['Label'],axis=1)\n",
    "\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Normalize the dataset using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "X = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "print(\"Dataset normalized using MinMaxScaler.\")\n",
    "\n",
    "X_train_cv, X_unseen_test, y_train_cv, y_unseen_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c270667-7892-44d8-b952-dc9a6940a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "start = datetime.now()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_cv):\n",
    "    X_train, X_test = X_train_cv.iloc[train_index], X_train_cv.iloc[test_index]\n",
    "    y_train, y_test = y_train_cv.iloc[train_index], y_train_cv.iloc[test_index]\n",
    "    \n",
    "    # Train the dt classifier\n",
    "    LR.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test fold\n",
    "    y_pred_test = LR.predict(X_test)\n",
    "    y_pred_train = LR.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics for the test fold\n",
    "    train_accuracies.append(accuracy_score(y_train, y_pred_train))\n",
    "    test_accuracies.append(accuracy_score(y_test, y_pred_test))\n",
    "    precisions.append(precision_score(y_test, y_pred_test, average='weighted'))\n",
    "    recalls.append(recall_score(y_test, y_pred_test, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Test the final model on unseen data\n",
    "y_unseen_pred = LR.predict(X_unseen_test)\n",
    "unseen_accuracy = accuracy_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_precision = precision_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_recall = recall_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_f1 = f1_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_conf_matrix = confusion_matrix(y_unseen_test, y_unseen_pred)\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a4b7ee-1ced-44e5-8b2f-71a50cdee3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix:\n",
      "512.70  36.00   8.40  46.00   7.70 188.30\n",
      " 16.50 746.10   0.00   0.00   4.10  27.70\n",
      "  4.10   0.10 794.50   0.00   0.80   0.00\n",
      " 25.50   0.00   0.00 774.10   0.00   0.00\n",
      "  4.70   0.00   0.00   0.00 798.80   0.00\n",
      " 14.70   0.00   0.00   0.00   0.30 788.90\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average confusion matrix for multi-class classification\n",
    "import numpy as np\n",
    "\n",
    "# Determine the number of classes from the confusion matrices\n",
    "num_classes = confusion_matrices[0].shape[0]\n",
    "\n",
    "# Initialize an array to store the sum of confusion matrices\n",
    "confusion_matrix_sum = np.zeros((num_classes, num_classes))\n",
    "\n",
    "# Sum up the confusion matrices from all folds\n",
    "for cm in confusion_matrices:\n",
    "    confusion_matrix_sum += cm\n",
    "\n",
    "# Compute the average confusion matrix\n",
    "average_conf_matrix = confusion_matrix_sum / len(confusion_matrices)\n",
    "\n",
    "# Display the average confusion matrix\n",
    "print(\"Average Confusion Matrix:\")\n",
    "max_width = max(len(\"{:.2f}\".format(value)) for row in average_conf_matrix for value in row)\n",
    "\n",
    "# Print each row with formatted values\n",
    "for row in average_conf_matrix:\n",
    "    print(\" \".join(f\"{value:>{max_width}.2f}\" for value in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2cf09b-de3f-4f70-b3c0-71cb092560c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training Accuracy: 0.9196296296296296\n",
      "Testing Accuracy: 0.9227083333333334\n",
      "Precision: 0.9260789809850678\n",
      "Recall: 0.9227083333333334\n",
      "F1-Score: 0.9192788437711313\n",
      "Confusion Matrix:\n",
      "[[481  43  11  37   6 183]\n",
      " [ 17 773   0   0   0  30]\n",
      " [  4   0 769   0   0   0]\n",
      " [ 19   0   0 775   0   0]\n",
      " [  4   0   0   0 803   0]\n",
      " [ 17   0   0   0   0 828]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.9206018518518518\n",
      "Testing Accuracy: 0.9154166666666667\n",
      "Precision: 0.9214798761975275\n",
      "Recall: 0.9154166666666667\n",
      "F1-Score: 0.9117923588084492\n",
      "Confusion Matrix:\n",
      "[[518  32   8  57   7 207]\n",
      " [ 20 722   0   0   6  29]\n",
      " [  6   0 806   0   0   0]\n",
      " [ 24   0   0 790   0   0]\n",
      " [  5   0   0   0 780   0]\n",
      " [  5   0   0   0   0 778]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9202546296296297\n",
      "Testing Accuracy: 0.916875\n",
      "Precision: 0.9205872120328296\n",
      "Recall: 0.916875\n",
      "F1-Score: 0.9138396871883261\n",
      "Confusion Matrix:\n",
      "[[500  33   7  43  11 196]\n",
      " [ 16 801   0   0   1  29]\n",
      " [  7   0 766   0   1   0]\n",
      " [ 34   0   0 791   0   0]\n",
      " [  2   0   0   0 767   0]\n",
      " [ 19   0   0   0   0 776]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.92\n",
      "Testing Accuracy: 0.9191666666666667\n",
      "Precision: 0.9228528494600107\n",
      "Recall: 0.9191666666666667\n",
      "F1-Score: 0.9158829675243807\n",
      "Confusion Matrix:\n",
      "[[533  38   5  56   9 182]\n",
      " [ 15 711   0   0   8  25]\n",
      " [  3   0 836   0   2   0]\n",
      " [ 21   0   0 751   0   0]\n",
      " [  4   0   0   0 799   0]\n",
      " [ 19   0   0   0   1 782]]\n",
      "\n",
      "Fold 5:\n",
      "Training Accuracy: 0.9198842592592592\n",
      "Testing Accuracy: 0.9197916666666667\n",
      "Precision: 0.9240286723801819\n",
      "Recall: 0.9197916666666667\n",
      "F1-Score: 0.9166402854964859\n",
      "Confusion Matrix:\n",
      "[[525  43   9  35  11 190]\n",
      " [ 10 752   0   0   5  28]\n",
      " [  3   0 788   0   1   0]\n",
      " [ 34   0   0 758   0   0]\n",
      " [  4   0   0   0 791   0]\n",
      " [ 12   0   0   0   0 801]]\n",
      "\n",
      "Fold 6:\n",
      "Training Accuracy: 0.9197222222222222\n",
      "Testing Accuracy: 0.9208333333333333\n",
      "Precision: 0.9232579959495129\n",
      "Recall: 0.9208333333333333\n",
      "F1-Score: 0.9177493175736229\n",
      "Confusion Matrix:\n",
      "[[513  39   9  50   7 173]\n",
      " [ 20 742   0   0   4  23]\n",
      " [  3   0 786   0   0   0]\n",
      " [ 30   0   0 784   0   0]\n",
      " [  7   0   0   0 822   0]\n",
      " [ 15   0   0   0   0 773]]\n",
      "\n",
      "Fold 7:\n",
      "Training Accuracy: 0.9199768518518519\n",
      "Testing Accuracy: 0.9197916666666667\n",
      "Precision: 0.9231724625044133\n",
      "Recall: 0.9197916666666667\n",
      "F1-Score: 0.916744520715957\n",
      "Confusion Matrix:\n",
      "[[497  35   9  42   8 186]\n",
      " [ 14 741   0   0   3  31]\n",
      " [  4   0 808   0   1   0]\n",
      " [ 24   0   0 777   0   0]\n",
      " [  7   0   0   0 789   0]\n",
      " [ 21   0   0   0   0 803]]\n",
      "\n",
      "Fold 8:\n",
      "Training Accuracy: 0.9197685185185185\n",
      "Testing Accuracy: 0.9214583333333334\n",
      "Precision: 0.9251088556837033\n",
      "Recall: 0.9214583333333334\n",
      "F1-Score: 0.9183736649163077\n",
      "Confusion Matrix:\n",
      "[[527  38  13  54   5 168]\n",
      " [ 15 728   0   0   4  33]\n",
      " [  5   0 804   0   1   0]\n",
      " [ 23   0   0 774   0   0]\n",
      " [  5   0   0   0 804   0]\n",
      " [ 12   0   0   0   1 786]]\n",
      "\n",
      "Fold 9:\n",
      "Training Accuracy: 0.9192592592592592\n",
      "Testing Accuracy: 0.9266666666666666\n",
      "Precision: 0.9306712167776378\n",
      "Recall: 0.9266666666666666\n",
      "F1-Score: 0.9243450178304486\n",
      "Confusion Matrix:\n",
      "[[539  28   8  37   9 176]\n",
      " [ 19 759   0   0   4  28]\n",
      " [  1   0 775   0   1   0]\n",
      " [ 24   0   0 778   0   0]\n",
      " [  3   0   0   0 813   0]\n",
      " [ 14   0   0   0   0 784]]\n",
      "\n",
      "Fold 10:\n",
      "Training Accuracy: 0.9205555555555556\n",
      "Testing Accuracy: 0.9154166666666667\n",
      "Precision: 0.9210447798995642\n",
      "Recall: 0.9154166666666667\n",
      "F1-Score: 0.9117908262608133\n",
      "Confusion Matrix:\n",
      "[[494  31   5  49   4 222]\n",
      " [ 19 732   0   0   6  21]\n",
      " [  5   1 807   0   1   0]\n",
      " [ 22   0   0 763   0   0]\n",
      " [  6   0   0   0 820   0]\n",
      " [ 13   0   0   0   1 778]]\n",
      "\n",
      "Average Training Accuracy: 0.9199652777777778\n",
      "Average Testing Accuracy: 0.9198124999999999\n",
      "Average Precision: 0.9238282901870448\n",
      "Average recall: 0.9198125000000001\n",
      "Average F1 Score: 0.9166437490085922\n",
      "Performance on Unseen Data:\n",
      "Accuracy: 0.9193333333333333\n",
      "Precision: 0.9237362877452645\n",
      "Recall: 0.9193333333333333\n",
      "F1-Score: 0.9161954992693279\n",
      "Confusion Matrix:\n",
      "[[1291   94   22  117   20  465]\n",
      " [  50 1917    0    0   12   77]\n",
      " [   7    1 1997    0    0    0]\n",
      " [  57    0    0 1947    0    0]\n",
      " [  16    1    0    0 1948    0]\n",
      " [  29    0    0    0    0 1932]]\n",
      "excution time:  0:00:04.613703\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics for each fold\n",
    "for i in range(10):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[i]}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1-Score: {f1_scores[i]}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrices[i]}\\n\")\n",
    "\n",
    "print(f\"Average Training Accuracy: {sum(train_accuracies) / 10}\")\n",
    "print(f\"Average Testing Accuracy: {sum(test_accuracies) / 10}\")\n",
    "print(f\"Average Precision: {sum(precisions) / 10}\")\n",
    "print(f\"Average recall: {sum(recalls) / 10}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / 10}\")\n",
    "\n",
    "# Print the performance on the unseen data\n",
    "print(\"Performance on Unseen Data:\")\n",
    "print(f\"Accuracy: {unseen_accuracy}\")\n",
    "print(f\"Precision: {unseen_precision}\")\n",
    "print(f\"Recall: {unseen_recall}\")\n",
    "print(f\"F1-Score: {unseen_f1}\")\n",
    "print(f\"Confusion Matrix:\\n{unseen_conf_matrix}\")\n",
    "print(\"excution time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b6f783-bcc2-4cf3-b5b3-ed834ec00a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('lr_multi.pkl', 'wb') as file:\n",
    "#     pickle.dump(LR, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
