{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a0d056-8595-4283-bef4-0d3a78edc141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df = pd.read_csv('research_traffic.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2476ebf8-f484-4735-b08a-1020f7e156a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count_of_Source_IP        int64\n",
      "Port_Count                int64\n",
      "Pair_Count_Ratio        float64\n",
      "Packet_Count_Diff         int64\n",
      "Lookup_Count_Diff         int64\n",
      "Protocol                  int64\n",
      "Average_Packet_Count    float64\n",
      "Average_Byte_Count      float64\n",
      "Packet_Std_Dev          float64\n",
      "Byte_Std_Dev            float64\n",
      "Duration_per_Flow       float64\n",
      "Label                     int64\n",
      "dtype: object\n",
      "70000\n",
      "70000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_of_Source_IP</th>\n",
       "      <th>Port_Count</th>\n",
       "      <th>Pair_Count_Ratio</th>\n",
       "      <th>Packet_Count_Diff</th>\n",
       "      <th>Lookup_Count_Diff</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Average_Packet_Count</th>\n",
       "      <th>Average_Byte_Count</th>\n",
       "      <th>Packet_Std_Dev</th>\n",
       "      <th>Byte_Std_Dev</th>\n",
       "      <th>Duration_per_Flow</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436913</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>145637.6667</td>\n",
       "      <td>3.567915e+09</td>\n",
       "      <td>24719.5</td>\n",
       "      <td>5.339086e+09</td>\n",
       "      <td>1.258000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436912</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>145637.3333</td>\n",
       "      <td>3.567915e+09</td>\n",
       "      <td>24721.0</td>\n",
       "      <td>5.339086e+09</td>\n",
       "      <td>1.254000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1006277</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>335425.6667</td>\n",
       "      <td>8.291520e+09</td>\n",
       "      <td>61289.5</td>\n",
       "      <td>1.240812e+10</td>\n",
       "      <td>2.587333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1006280</td>\n",
       "      <td>6</td>\n",
       "      <td>335426.0000</td>\n",
       "      <td>8.291520e+09</td>\n",
       "      <td>61288.0</td>\n",
       "      <td>1.240812e+10</td>\n",
       "      <td>2.592000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1605562</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>535187.3333</td>\n",
       "      <td>1.321503e+10</td>\n",
       "      <td>97006.0</td>\n",
       "      <td>1.977597e+10</td>\n",
       "      <td>3.926000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count_of_Source_IP  Port_Count  Pair_Count_Ratio  Packet_Count_Diff  \\\n",
       "0                   2           2               1.0             436913   \n",
       "1                   2           2               1.0             436912   \n",
       "2                   2           2               1.0            1006277   \n",
       "3                   2           2               0.0                  1   \n",
       "4                   2           2               1.0            1605562   \n",
       "\n",
       "   Lookup_Count_Diff  Protocol  Average_Packet_Count  Average_Byte_Count  \\\n",
       "0                  1         6           145637.6667        3.567915e+09   \n",
       "1                  1         6           145637.3333        3.567915e+09   \n",
       "2                  1         6           335425.6667        8.291520e+09   \n",
       "3            1006280         6           335426.0000        8.291520e+09   \n",
       "4                  6         6           535187.3333        1.321503e+10   \n",
       "\n",
       "   Packet_Std_Dev  Byte_Std_Dev  Duration_per_Flow  Label  \n",
       "0         24719.5  5.339086e+09           1.258000      0  \n",
       "1         24721.0  5.339086e+09           1.254000      0  \n",
       "2         61289.5  1.240812e+10           2.587333      0  \n",
       "3         61288.0  1.240812e+10           2.592000      0  \n",
       "4         97006.0  1.977597e+10           3.926000      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df['Label'].value_counts()[1])\n",
    "print(df['Label'].value_counts()[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e70c9ef5-bfa0-469f-9c30-b2c3c20cd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_cols=df.dtypes[df.dtypes == \"object\"].index.values.tolist()\n",
    "# print(obj_cols)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# #Encode labels of multiple columns at once\n",
    "\n",
    "# df[obj_cols] = df[obj_cols].astype(str)\n",
    "# df[obj_cols] = df[obj_cols].apply(LabelEncoder().fit_transform)\n",
    "# #\n",
    "# # Print head\n",
    "# #\n",
    "# print(df.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6108716-8e94-4552-ab5e-1335e591c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset normalized using MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "y = df.Label\n",
    "X = df.drop(['Label'],axis=1)\n",
    "\n",
    "# Normalize the dataset using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "X = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "print(\"Dataset normalized using MinMaxScaler.\")\n",
    "\n",
    "prob_model = GaussianNB()\n",
    "\n",
    "X_train_cv, X_unseen_test, y_train_cv, y_unseen_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ac528e-6fb9-4659-ba00-a05fefe43799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excution time:  0:00:00.668737\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "start = datetime.now()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_cv):\n",
    "    X_train, X_test = X_train_cv.iloc[train_index], X_train_cv.iloc[test_index]\n",
    "    y_train, y_test = y_train_cv.iloc[train_index], y_train_cv.iloc[test_index]\n",
    "    \n",
    "    # Train the prob classifier\n",
    "    prob_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test fold\n",
    "    y_pred_test = prob_model.predict(X_test)\n",
    "    y_pred_train = prob_model.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics for the test fold\n",
    "    train_accuracies.append(accuracy_score(y_train, y_pred_train))\n",
    "    test_accuracies.append(accuracy_score(y_test, y_pred_test))\n",
    "    precisions.append(precision_score(y_test, y_pred_test))\n",
    "    recalls.append(recall_score(y_test, y_pred_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_test))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Test the final model on unseen data\n",
    "y_unseen_pred = prob_model.predict(X_unseen_test)\n",
    "unseen_accuracy = accuracy_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_precision = precision_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_recall = recall_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_f1 = f1_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_conf_matrix = confusion_matrix(y_unseen_test, y_unseen_pred)\n",
    "end = datetime.now()\n",
    "print(\"excution time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "948af3a4-5c00-443f-9768-7527ad343a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix:\n",
      "[[4893.   720.9]\n",
      " [  58.4 5527.7]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average confusion matrix\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an array to store the sum of confusion matrices\n",
    "confusion_matrix_sum = np.zeros((2, 2))  # Adjust the size if multi-class classification\n",
    "\n",
    "# During the cross-validation loop, confusion matrices were already calculated\n",
    "# Here, we'll sum up those matrices (assumes `confusion_matrices` contains all fold matrices)\n",
    "for cm in confusion_matrices:\n",
    "    confusion_matrix_sum += cm\n",
    "\n",
    "# Compute the average confusion matrix\n",
    "average_conf_matrix = confusion_matrix_sum / 10\n",
    "\n",
    "# Display the average confusion matrix\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(average_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f59bdf65-b5bb-49ca-af02-919c88df0c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training Accuracy: 0.9296924603174603\n",
      "Testing Accuracy: 0.9325\n",
      "Precision: 0.8868828886403579\n",
      "Recall: 0.991427040542954\n",
      "F1-Score: 0.9362455726092089\n",
      "Confusion Matrix:\n",
      "[[4893  708]\n",
      " [  48 5551]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.9311111111111111\n",
      "Testing Accuracy: 0.9296428571428571\n",
      "Precision: 0.8846401028277635\n",
      "Recall: 0.9874461979913917\n",
      "F1-Score: 0.9332203389830509\n",
      "Confusion Matrix:\n",
      "[[4906  718]\n",
      " [  70 5506]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9303373015873015\n",
      "Testing Accuracy: 0.9309821428571429\n",
      "Precision: 0.8853573687539532\n",
      "Recall: 0.991499911457411\n",
      "F1-Score: 0.9354272825996157\n",
      "Confusion Matrix:\n",
      "[[4828  725]\n",
      " [  48 5599]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.929890873015873\n",
      "Testing Accuracy: 0.9308928571428572\n",
      "Precision: 0.8832634633989036\n",
      "Recall: 0.9909551374819102\n",
      "F1-Score: 0.9340153452685422\n",
      "Confusion Matrix:\n",
      "[[4948  724]\n",
      " [  50 5478]]\n",
      "\n",
      "Fold 5:\n",
      "Training Accuracy: 0.9297619047619048\n",
      "Testing Accuracy: 0.9305357142857142\n",
      "Precision: 0.8848978288633461\n",
      "Recall: 0.9898214285714285\n",
      "F1-Score: 0.9344234659474039\n",
      "Confusion Matrix:\n",
      "[[4879  721]\n",
      " [  57 5543]]\n",
      "\n",
      "Fold 6:\n",
      "Training Accuracy: 0.9309126984126984\n",
      "Testing Accuracy: 0.9290178571428571\n",
      "Precision: 0.8826636785657116\n",
      "Recall: 0.9888809182209469\n",
      "F1-Score: 0.9327581832022329\n",
      "Confusion Matrix:\n",
      "[[4891  733]\n",
      " [  62 5514]]\n",
      "\n",
      "Fold 7:\n",
      "Training Accuracy: 0.9307539682539683\n",
      "Testing Accuracy: 0.9323214285714285\n",
      "Precision: 0.8893344025661588\n",
      "Recall: 0.9878852663459825\n",
      "F1-Score: 0.9360229574611749\n",
      "Confusion Matrix:\n",
      "[[4897  690]\n",
      " [  68 5545]]\n",
      "\n",
      "Fold 8:\n",
      "Training Accuracy: 0.9310019841269841\n",
      "Testing Accuracy: 0.930625\n",
      "Precision: 0.885576923076923\n",
      "Recall: 0.9887278582930756\n",
      "F1-Score: 0.9343139741313721\n",
      "Confusion Matrix:\n",
      "[[4897  714]\n",
      " [  63 5526]]\n",
      "\n",
      "Fold 9:\n",
      "Training Accuracy: 0.9298313492063492\n",
      "Testing Accuracy: 0.933125\n",
      "Precision: 0.888351080993869\n",
      "Recall: 0.9897537300017976\n",
      "F1-Score: 0.9363149392058498\n",
      "Confusion Matrix:\n",
      "[[4945  692]\n",
      " [  57 5506]]\n",
      "\n",
      "Fold 10:\n",
      "Training Accuracy: 0.9312202380952381\n",
      "Testing Accuracy: 0.9245535714285714\n",
      "Precision: 0.8754171301446051\n",
      "Recall: 0.989048473967684\n",
      "F1-Score: 0.9287701256006069\n",
      "Confusion Matrix:\n",
      "[[4846  784]\n",
      " [  61 5509]]\n",
      "\n",
      "Average Training Accuracy: 0.930451388888889\n",
      "Average Testing Accuracy: 0.9304196428571428\n",
      "Average Precision: 0.8846384867831592\n",
      "Average recall: 0.9895445962874581\n",
      "Average F1 Score: 0.9341512185009059\n",
      "Performance on Unseen Data:\n",
      "Accuracy: 0.9311428571428572\n",
      "Precision: 0.8873310917972467\n",
      "Recall: 0.9892495933234317\n",
      "F1-Score: 0.9355227075112033\n",
      "Confusion Matrix:\n",
      "[[12085  1776]\n",
      " [  152 13987]]\n",
      "excution time:  0:00:00.668737\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics for each fold\n",
    "for i in range(10):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[i]}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1-Score: {f1_scores[i]}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrices[i]}\\n\")\n",
    "\n",
    "print(f\"Average Training Accuracy: {sum(train_accuracies) / 10}\")\n",
    "print(f\"Average Testing Accuracy: {sum(test_accuracies) / 10}\")\n",
    "print(f\"Average Precision: {sum(precisions) / 10}\")\n",
    "print(f\"Average recall: {sum(recalls) / 10}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / 10}\")\n",
    "\n",
    "# Print the performance on the unseen data\n",
    "print(\"Performance on Unseen Data:\")\n",
    "print(f\"Accuracy: {unseen_accuracy}\")\n",
    "print(f\"Precision: {unseen_precision}\")\n",
    "print(f\"Recall: {unseen_recall}\")\n",
    "print(f\"F1-Score: {unseen_f1}\")\n",
    "print(f\"Confusion Matrix:\\n{unseen_conf_matrix}\")\n",
    "print(\"excution time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd33b968-7850-4ecc-870c-1453bc82f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the metrics for each fold\n",
    "# for i in range(5):\n",
    "#     print(f\"Fold {i+1}:\")\n",
    "#     print(f\"Accuracy: {accuracies[i]}\")\n",
    "#     print(f\"Precision: {precisions[i]}\")\n",
    "#     print(f\"Recall: {recalls[i]}\")\n",
    "#     print(f\"F1-Score: {f1_scores[i]}\")\n",
    "#     print(f\"Confusion Matrix:\\n{confusion_matrices[i]}\\n\")\n",
    "\n",
    "# # Print the performance on the unseen data\n",
    "# print(\"Performance on Unseen Data:\")\n",
    "# print(f\"Accuracy: {unseen_accuracy}\")\n",
    "# print(f\"Precision: {unseen_precision}\")\n",
    "# print(f\"Recall: {unseen_recall}\")\n",
    "# print(f\"F1-Score: {unseen_f1}\")\n",
    "# print(f\"Confusion Matrix:\\n{unseen_conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b716ff99-8352-4962-a4e5-9b599d25878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('nb_binary.pkl', 'wb') as file:\n",
    "#     pickle.dump(prob_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
