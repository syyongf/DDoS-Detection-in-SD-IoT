{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be54130f-a0b8-4cea-a078-8a1334c56b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('research_traffic.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2eaa4d-725c-42a9-9509-b93a9a697fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count_of_Source_IP        int64\n",
      "Port_Count                int64\n",
      "Pair_Count_Ratio        float64\n",
      "Packet_Count_Diff         int64\n",
      "Lookup_Count_Diff         int64\n",
      "Protocol                  int64\n",
      "Average_Packet_Count    float64\n",
      "Average_Byte_Count      float64\n",
      "Packet_Std_Dev          float64\n",
      "Byte_Std_Dev            float64\n",
      "Duration_per_Flow       float64\n",
      "Label                     int64\n",
      "dtype: object\n",
      "70000\n",
      "70000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_of_Source_IP</th>\n",
       "      <th>Port_Count</th>\n",
       "      <th>Pair_Count_Ratio</th>\n",
       "      <th>Packet_Count_Diff</th>\n",
       "      <th>Lookup_Count_Diff</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Average_Packet_Count</th>\n",
       "      <th>Average_Byte_Count</th>\n",
       "      <th>Packet_Std_Dev</th>\n",
       "      <th>Byte_Std_Dev</th>\n",
       "      <th>Duration_per_Flow</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436913</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>145637.6667</td>\n",
       "      <td>3.567915e+09</td>\n",
       "      <td>24719.5</td>\n",
       "      <td>5.339086e+09</td>\n",
       "      <td>1.258000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436912</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>145637.3333</td>\n",
       "      <td>3.567915e+09</td>\n",
       "      <td>24721.0</td>\n",
       "      <td>5.339086e+09</td>\n",
       "      <td>1.254000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1006277</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>335425.6667</td>\n",
       "      <td>8.291520e+09</td>\n",
       "      <td>61289.5</td>\n",
       "      <td>1.240812e+10</td>\n",
       "      <td>2.587333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1006280</td>\n",
       "      <td>6</td>\n",
       "      <td>335426.0000</td>\n",
       "      <td>8.291520e+09</td>\n",
       "      <td>61288.0</td>\n",
       "      <td>1.240812e+10</td>\n",
       "      <td>2.592000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1605562</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>535187.3333</td>\n",
       "      <td>1.321503e+10</td>\n",
       "      <td>97006.0</td>\n",
       "      <td>1.977597e+10</td>\n",
       "      <td>3.926000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count_of_Source_IP  Port_Count  Pair_Count_Ratio  Packet_Count_Diff  \\\n",
       "0                   2           2               1.0             436913   \n",
       "1                   2           2               1.0             436912   \n",
       "2                   2           2               1.0            1006277   \n",
       "3                   2           2               0.0                  1   \n",
       "4                   2           2               1.0            1605562   \n",
       "\n",
       "   Lookup_Count_Diff  Protocol  Average_Packet_Count  Average_Byte_Count  \\\n",
       "0                  1         6           145637.6667        3.567915e+09   \n",
       "1                  1         6           145637.3333        3.567915e+09   \n",
       "2                  1         6           335425.6667        8.291520e+09   \n",
       "3            1006280         6           335426.0000        8.291520e+09   \n",
       "4                  6         6           535187.3333        1.321503e+10   \n",
       "\n",
       "   Packet_Std_Dev  Byte_Std_Dev  Duration_per_Flow  Label  \n",
       "0         24719.5  5.339086e+09           1.258000      0  \n",
       "1         24721.0  5.339086e+09           1.254000      0  \n",
       "2         61289.5  1.240812e+10           2.587333      0  \n",
       "3         61288.0  1.240812e+10           2.592000      0  \n",
       "4         97006.0  1.977597e+10           3.926000      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df['Label'].value_counts()[1])\n",
    "print(df['Label'].value_counts()[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6623849d-3cb4-4315-b7f6-94666c3533d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_cols=df.dtypes[df.dtypes == \"object\"].index.values.tolist()\n",
    "# print(obj_cols)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# #Encode labels of multiple columns at once\n",
    "\n",
    "# df[obj_cols] = df[obj_cols].astype(str)\n",
    "# df[obj_cols] = df[obj_cols].apply(LabelEncoder().fit_transform)\n",
    "# #\n",
    "# # Print head\n",
    "# #\n",
    "# print(df.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566a0563-73e8-491c-a979-7132ecfd14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset normalized using MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "y = df.Label\n",
    "X = df.drop(['Label'],axis=1)\n",
    "\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Normalize the dataset using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "X = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "print(\"Dataset normalized using MinMaxScaler.\")\n",
    "\n",
    "X_train_cv, X_unseen_test, y_train_cv, y_unseen_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c270667-7892-44d8-b952-dc9a6940a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "start = datetime.now()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_cv):\n",
    "    X_train, X_test = X_train_cv.iloc[train_index], X_train_cv.iloc[test_index]\n",
    "    y_train, y_test = y_train_cv.iloc[train_index], y_train_cv.iloc[test_index]\n",
    "    \n",
    "    # Train the dt classifier\n",
    "    LR.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test fold\n",
    "    y_pred_test = LR.predict(X_test)\n",
    "    y_pred_train = LR.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics for the test fold\n",
    "    train_accuracies.append(accuracy_score(y_train, y_pred_train))\n",
    "    test_accuracies.append(accuracy_score(y_test, y_pred_test))\n",
    "    precisions.append(precision_score(y_test, y_pred_test))\n",
    "    recalls.append(recall_score(y_test, y_pred_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_test))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Test the final model on unseen data\n",
    "y_unseen_pred = LR.predict(X_unseen_test)\n",
    "unseen_accuracy = accuracy_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_precision = precision_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_recall = recall_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_f1 = f1_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_conf_matrix = confusion_matrix(y_unseen_test, y_unseen_pred)\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82a4b7ee-1ced-44e5-8b2f-71a50cdee3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix:\n",
      "[[5477.6  136.3]\n",
      " [ 131.3 5454.8]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average confusion matrix\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an array to store the sum of confusion matrices\n",
    "confusion_matrix_sum = np.zeros((2, 2))  # Adjust the size if multi-class classification\n",
    "\n",
    "# During the cross-validation loop, confusion matrices were already calculated\n",
    "# Here, we'll sum up those matrices (assumes `confusion_matrices` contains all fold matrices)\n",
    "for cm in confusion_matrices:\n",
    "    confusion_matrix_sum += cm\n",
    "\n",
    "# Compute the average confusion matrix\n",
    "average_conf_matrix = confusion_matrix_sum / 10\n",
    "\n",
    "# Display the average confusion matrix\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(average_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2cf09b-de3f-4f70-b3c0-71cb092560c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training Accuracy: 0.9758829365079366\n",
      "Testing Accuracy: 0.9782142857142857\n",
      "Precision: 0.9771876670825165\n",
      "Recall: 0.9792820146454724\n",
      "F1-Score: 0.9782337198929527\n",
      "Confusion Matrix:\n",
      "[[5473  128]\n",
      " [ 116 5483]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.9763392857142857\n",
      "Testing Accuracy: 0.9750892857142858\n",
      "Precision: 0.9743865305391367\n",
      "Recall: 0.975609756097561\n",
      "F1-Score: 0.9749977596558831\n",
      "Confusion Matrix:\n",
      "[[5481  143]\n",
      " [ 136 5440]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9760218253968254\n",
      "Testing Accuracy: 0.9766964285714286\n",
      "Precision: 0.9752912107306742\n",
      "Recall: 0.978572693465557\n",
      "F1-Score: 0.9769291964996022\n",
      "Confusion Matrix:\n",
      "[[5413  140]\n",
      " [ 121 5526]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.9759523809523809\n",
      "Testing Accuracy: 0.976875\n",
      "Precision: 0.9764876107795262\n",
      "Recall: 0.9766642547033285\n",
      "F1-Score: 0.9765759247535498\n",
      "Confusion Matrix:\n",
      "[[5542  130]\n",
      " [ 129 5399]]\n",
      "\n",
      "Fold 5:\n",
      "Training Accuracy: 0.9758730158730159\n",
      "Testing Accuracy: 0.9777678571428572\n",
      "Precision: 0.9787081767758097\n",
      "Recall: 0.9767857142857143\n",
      "F1-Score: 0.977746000536241\n",
      "Confusion Matrix:\n",
      "[[5481  119]\n",
      " [ 130 5470]]\n",
      "\n",
      "Fold 6:\n",
      "Training Accuracy: 0.9760615079365079\n",
      "Testing Accuracy: 0.9759821428571429\n",
      "Precision: 0.97733405288721\n",
      "Recall: 0.9743543758967002\n",
      "F1-Score: 0.9758419398293668\n",
      "Confusion Matrix:\n",
      "[[5498  126]\n",
      " [ 143 5433]]\n",
      "\n",
      "Fold 7:\n",
      "Training Accuracy: 0.976279761904762\n",
      "Testing Accuracy: 0.9744642857142857\n",
      "Precision: 0.9741855082784404\n",
      "Recall: 0.9748797434526991\n",
      "F1-Score: 0.9745325022261799\n",
      "Confusion Matrix:\n",
      "[[5442  145]\n",
      " [ 141 5472]]\n",
      "\n",
      "Fold 8:\n",
      "Training Accuracy: 0.9761607142857143\n",
      "Testing Accuracy: 0.9757142857142858\n",
      "Precision: 0.9763483246729977\n",
      "Recall: 0.9749507962068349\n",
      "F1-Score: 0.975649059982095\n",
      "Confusion Matrix:\n",
      "[[5479  132]\n",
      " [ 140 5449]]\n",
      "\n",
      "Fold 9:\n",
      "Training Accuracy: 0.9761805555555556\n",
      "Testing Accuracy: 0.9751785714285715\n",
      "Precision: 0.973651191969887\n",
      "Recall: 0.976451554916412\n",
      "F1-Score: 0.9750493627714952\n",
      "Confusion Matrix:\n",
      "[[5490  147]\n",
      " [ 131 5432]]\n",
      "\n",
      "Fold 10:\n",
      "Training Accuracy: 0.9762301587301587\n",
      "Testing Accuracy: 0.9750892857142858\n",
      "Precision: 0.9726639271038056\n",
      "Recall: 0.9773788150807899\n",
      "F1-Score: 0.9750156711739948\n",
      "Confusion Matrix:\n",
      "[[5477  153]\n",
      " [ 126 5444]]\n",
      "\n",
      "Average Training Accuracy: 0.9760982142857143\n",
      "Average Testing Accuracy: 0.9761071428571428\n",
      "Average Precision: 0.9756244200820005\n",
      "Average recall: 0.976492971875107\n",
      "Average F1 Score: 0.976057113732136\n",
      "Performance on Unseen Data:\n",
      "Accuracy: 0.9755357142857143\n",
      "Precision: 0.9762140733399405\n",
      "Recall: 0.9753165004597213\n",
      "F1-Score: 0.9757650804882363\n",
      "Confusion Matrix:\n",
      "[[13525   336]\n",
      " [  349 13790]]\n",
      "excution time:  0:00:02.908431\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics for each fold\n",
    "for i in range(10):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[i]}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1-Score: {f1_scores[i]}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrices[i]}\\n\")\n",
    "\n",
    "print(f\"Average Training Accuracy: {sum(train_accuracies) / 10}\")\n",
    "print(f\"Average Testing Accuracy: {sum(test_accuracies) / 10}\")\n",
    "print(f\"Average Precision: {sum(precisions) / 10}\")\n",
    "print(f\"Average recall: {sum(recalls) / 10}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / 10}\")\n",
    "\n",
    "# Print the performance on the unseen data\n",
    "print(\"Performance on Unseen Data:\")\n",
    "print(f\"Accuracy: {unseen_accuracy}\")\n",
    "print(f\"Precision: {unseen_precision}\")\n",
    "print(f\"Recall: {unseen_recall}\")\n",
    "print(f\"F1-Score: {unseen_f1}\")\n",
    "print(f\"Confusion Matrix:\\n{unseen_conf_matrix}\")\n",
    "print(\"excution time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e2ac18-5753-45cd-8ef2-7691cc369c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('lr_binary.pkl', 'wb') as file:\n",
    "#     pickle.dump(LR, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
