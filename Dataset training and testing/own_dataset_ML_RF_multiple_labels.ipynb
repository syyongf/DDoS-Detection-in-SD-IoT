{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b3d806-4ff7-4a58-822a-487ec28c0072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df = pd.read_csv('research_traffic_multiple_labels.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d5044e-30e4-4889-b8b5-cf9446f8051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Source IP        int64\n",
      "Port Count                int64\n",
      "Pair Count Ratio        float64\n",
      "Packet Count Diff         int64\n",
      "Lookup Count Diff         int64\n",
      "Protocol                  int64\n",
      "Average Packet Count    float64\n",
      "Average Byte Count      float64\n",
      "Packet Std Dev          float64\n",
      "Byte Std Dev            float64\n",
      "Duration per Flow       float64\n",
      "Label                     int64\n",
      "dtype: object\n",
      "10000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count of Source IP</th>\n",
       "      <th>Port Count</th>\n",
       "      <th>Pair Count Ratio</th>\n",
       "      <th>Packet Count Diff</th>\n",
       "      <th>Lookup Count Diff</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Average Packet Count</th>\n",
       "      <th>Average Byte Count</th>\n",
       "      <th>Packet Std Dev</th>\n",
       "      <th>Byte Std Dev</th>\n",
       "      <th>Duration per Flow</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>4.788991</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>28.466647</td>\n",
       "      <td>0.668020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>1.596330</td>\n",
       "      <td>0.095342</td>\n",
       "      <td>16.589551</td>\n",
       "      <td>0.419081</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>4.150459</td>\n",
       "      <td>0.355016</td>\n",
       "      <td>61.772825</td>\n",
       "      <td>2.946281</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>4.788991</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>28.466647</td>\n",
       "      <td>2.674461</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count of Source IP  Port Count  Pair Count Ratio  Packet Count Diff  \\\n",
       "0                 545         545               0.0                  2   \n",
       "1                 545         545               0.0                 10   \n",
       "2                  52          52               0.0                  3   \n",
       "3                 545         545               0.0                 13   \n",
       "4                 545         545               0.0                  2   \n",
       "\n",
       "   Lookup Count Diff  Protocol  Average Packet Count  Average Byte Count  \\\n",
       "0                 43         6              0.027523            4.788991   \n",
       "1                  0         6              0.009174            1.596330   \n",
       "2                  0         6              0.000000            0.000000   \n",
       "3                 21         6              0.023853            4.150459   \n",
       "4                131         6              0.027523            4.788991   \n",
       "\n",
       "   Packet Std Dev  Byte Std Dev  Duration per Flow  Label  \n",
       "0        0.163601     28.466647           0.668020      3  \n",
       "1        0.095342     16.589551           0.419081      3  \n",
       "2        0.000000      0.000000           0.018792      3  \n",
       "3        0.355016     61.772825           2.946281      3  \n",
       "4        0.163601     28.466647           2.674461      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(df.dtypes)\n",
    "print(df['Label'].value_counts()[1])\n",
    "print(df['Label'].value_counts()[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb6bce6-e849-43c6-b3c9-d456368ac9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # obj_cols=df.dtypes[df.dtypes == \"object\"].index.values.tolist()\n",
    "# # print(obj_cols)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# #Encode labels of multiple columns at once\n",
    "\n",
    "# df[obj_cols] = df[obj_cols].astype(str)\n",
    "# df[obj_cols] = df[obj_cols].apply(LabelEncoder().fit_transform)\n",
    "# #\n",
    "# # Print head\n",
    "# #\n",
    "# print(df.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa701bd-bb1b-4e89-86c2-3c623d9b981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset normalized using MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score, make_scorer\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
    "\n",
    "rnd = RandomForestClassifier(n_estimators = 100, criterion = 'entropy')\n",
    "\n",
    "y = df.Label\n",
    "X = df.drop(['Label'],axis=1)\n",
    "\n",
    "# Normalize the dataset using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "X = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "print(\"Dataset normalized using MinMaxScaler.\")\n",
    "\n",
    "# # Scale the dataset using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "X_train_cv, X_unseen_test, y_train_cv, y_unseen_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c760dda-b4ee-4dd7-90ba-dd0518bafd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excution time:  0:01:05.902878\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "start = datetime.now()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_cv):\n",
    "    X_train, X_test = X_train_cv.iloc[train_index], X_train_cv.iloc[test_index]\n",
    "    y_train, y_test = y_train_cv.iloc[train_index], y_train_cv.iloc[test_index]\n",
    "    \n",
    "    # Train the RF classifier\n",
    "    rnd.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test fold\n",
    "    y_pred_test = rnd.predict(X_test)\n",
    "    y_pred_train = rnd.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics for the test fold\n",
    "    train_accuracies.append(accuracy_score(y_train, y_pred_train))\n",
    "    test_accuracies.append(accuracy_score(y_test, y_pred_test))\n",
    "    precisions.append(precision_score(y_test, y_pred_test, average='weighted'))\n",
    "    recalls.append(recall_score(y_test, y_pred_test, average='weighted'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Test the final model on unseen data\n",
    "y_unseen_pred = rnd.predict(X_unseen_test)\n",
    "unseen_accuracy = accuracy_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_precision = precision_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_recall = recall_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_f1 = f1_score(y_unseen_test, y_unseen_pred, average='weighted')\n",
    "unseen_conf_matrix = confusion_matrix(y_unseen_test, y_unseen_pred)\n",
    "end = datetime.now()\n",
    "print(\"excution time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e06648-e8af-4a5a-a1f9-975f94b42f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix:\n",
      "612.30  34.40   0.20  39.60   0.30 112.30\n",
      "  6.40 772.50   0.20   0.00   0.20  15.10\n",
      "  1.50   0.40 797.50   0.00   0.00   0.10\n",
      "  0.10   0.00   0.00 799.30   0.00   0.20\n",
      "  1.60   0.00   0.00   0.00 801.90   0.00\n",
      " 52.70   2.30   0.30   0.00   0.00 748.60\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average confusion matrix for multi-class classification\n",
    "import numpy as np\n",
    "\n",
    "# Determine the number of classes from the confusion matrices\n",
    "num_classes = confusion_matrices[0].shape[0]\n",
    "\n",
    "# Initialize an array to store the sum of confusion matrices\n",
    "confusion_matrix_sum = np.zeros((num_classes, num_classes))\n",
    "\n",
    "# Sum up the confusion matrices from all folds\n",
    "for cm in confusion_matrices:\n",
    "    confusion_matrix_sum += cm\n",
    "\n",
    "# Compute the average confusion matrix\n",
    "average_conf_matrix = confusion_matrix_sum / len(confusion_matrices)\n",
    "\n",
    "# Display the average confusion matrix\n",
    "print(\"Average Confusion Matrix:\")\n",
    "max_width = max(len(\"{:.2f}\".format(value)) for row in average_conf_matrix for value in row)\n",
    "\n",
    "# Print each row with formatted values\n",
    "for row in average_conf_matrix:\n",
    "    print(\" \".join(f\"{value:>{max_width}.2f}\" for value in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c29e3b50-cb72-4f68-9fa7-a0679b9cfcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training Accuracy: 0.9789351851851852\n",
      "Testing Accuracy: 0.9454166666666667\n",
      "Precision: 0.945137177409953\n",
      "Recall: 0.9454166666666667\n",
      "F1-Score: 0.9441209237334859\n",
      "Confusion Matrix:\n",
      "[[579  42   0  31   0 109]\n",
      " [  7 802   0   0   0  11]\n",
      " [  1   0 772   0   0   0]\n",
      " [  0   0   0 794   0   0]\n",
      " [  3   0   0   0 804   0]\n",
      " [ 57   1   0   0   0 787]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.9767361111111111\n",
      "Testing Accuracy: 0.9395833333333333\n",
      "Precision: 0.9411221351635686\n",
      "Recall: 0.9395833333333333\n",
      "F1-Score: 0.938330199799719\n",
      "Confusion Matrix:\n",
      "[[624  30   0  45   1 129]\n",
      " [  8 746   1   0   0  22]\n",
      " [  0   1 811   0   0   0]\n",
      " [  0   0   0 814   0   0]\n",
      " [  4   0   0   0 781   0]\n",
      " [ 46   3   0   0   0 734]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9778009259259259\n",
      "Testing Accuracy: 0.944375\n",
      "Precision: 0.9453363434092145\n",
      "Recall: 0.944375\n",
      "F1-Score: 0.9432084037429619\n",
      "Confusion Matrix:\n",
      "[[602  31   0  37   2 118]\n",
      " [  6 822   0   0   0  19]\n",
      " [  2   1 771   0   0   0]\n",
      " [  1   0   0 823   0   1]\n",
      " [  1   0   0   0 768   0]\n",
      " [ 46   1   1   0   0 747]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.9776851851851852\n",
      "Testing Accuracy: 0.9410416666666667\n",
      "Precision: 0.9412251749726962\n",
      "Recall: 0.9410416666666667\n",
      "F1-Score: 0.9396220348594161\n",
      "Confusion Matrix:\n",
      "[[624  38   0  48   0 113]\n",
      " [  9 737   1   0   0  12]\n",
      " [  2   1 838   0   0   0]\n",
      " [  0   0   0 772   0   0]\n",
      " [  1   0   0   0 802   0]\n",
      " [ 54   4   0   0   0 744]]\n",
      "\n",
      "Fold 5:\n",
      "Training Accuracy: 0.9797916666666666\n",
      "Testing Accuracy: 0.9441666666666667\n",
      "Precision: 0.944595935669541\n",
      "Recall: 0.9441666666666667\n",
      "F1-Score: 0.942767365127695\n",
      "Confusion Matrix:\n",
      "[[617  43   1  31   0 121]\n",
      " [  1 783   0   0   1  10]\n",
      " [  2   0 789   0   0   1]\n",
      " [  0   0   0 792   0   0]\n",
      " [  0   0   0   0 795   0]\n",
      " [ 56   1   0   0   0 756]]\n",
      "\n",
      "Fold 6:\n",
      "Training Accuracy: 0.9792361111111111\n",
      "Testing Accuracy: 0.943125\n",
      "Precision: 0.9427688720122288\n",
      "Recall: 0.943125\n",
      "F1-Score: 0.9419275554637594\n",
      "Confusion Matrix:\n",
      "[[609  40   0  42   0 100]\n",
      " [  9 768   0   0   0  12]\n",
      " [  3   0 786   0   0   0]\n",
      " [  0   0   0 813   0   1]\n",
      " [  2   0   0   0 827   0]\n",
      " [ 59   5   0   0   0 724]]\n",
      "\n",
      "Fold 7:\n",
      "Training Accuracy: 0.9787731481481482\n",
      "Testing Accuracy: 0.9420833333333334\n",
      "Precision: 0.9418271500148852\n",
      "Recall: 0.9420833333333334\n",
      "F1-Score: 0.9410754189680254\n",
      "Confusion Matrix:\n",
      "[[601  31   0  38   0 107]\n",
      " [  4 763   0   0   0  22]\n",
      " [  1   0 812   0   0   0]\n",
      " [  0   0   0 801   0   0]\n",
      " [  0   0   0   0 796   0]\n",
      " [ 71   3   1   0   0 749]]\n",
      "\n",
      "Fold 8:\n",
      "Training Accuracy: 0.9777083333333333\n",
      "Testing Accuracy: 0.9483333333333334\n",
      "Precision: 0.9489682433888473\n",
      "Recall: 0.9483333333333334\n",
      "F1-Score: 0.9470975317270169\n",
      "Confusion Matrix:\n",
      "[[625  36   0  48   0  96]\n",
      " [  5 759   0   0   0  16]\n",
      " [  2   1 807   0   0   0]\n",
      " [  0   0   0 797   0   0]\n",
      " [  0   0   0   0 809   0]\n",
      " [ 41   3   0   0   0 755]]\n",
      "\n",
      "Fold 9:\n",
      "Training Accuracy: 0.979212962962963\n",
      "Testing Accuracy: 0.95\n",
      "Precision: 0.9505336386901873\n",
      "Recall: 0.95\n",
      "F1-Score: 0.9492076697673235\n",
      "Confusion Matrix:\n",
      "[[634  24   1  33   0 105]\n",
      " [  7 785   0   0   1  17]\n",
      " [  0   0 777   0   0   0]\n",
      " [  0   0   0 802   0   0]\n",
      " [  1   0   0   0 815   0]\n",
      " [ 49   2   0   0   0 747]]\n",
      "\n",
      "Fold 10:\n",
      "Training Accuracy: 0.9794444444444445\n",
      "Testing Accuracy: 0.94375\n",
      "Precision: 0.9444514309037648\n",
      "Recall: 0.94375\n",
      "F1-Score: 0.9424203179955434\n",
      "Confusion Matrix:\n",
      "[[608  29   0  43   0 125]\n",
      " [  8 760   0   0   0  10]\n",
      " [  2   0 812   0   0   0]\n",
      " [  0   0   0 785   0   0]\n",
      " [  4   0   0   0 822   0]\n",
      " [ 48   0   1   0   0 743]]\n",
      "\n",
      "Average Training Accuracy: 0.9785324074074074\n",
      "Average Testing Accuracy: 0.9441875\n",
      "Average Precision: 0.9445966101634887\n",
      "Average recall: 0.9441875\n",
      "Average F1 Score: 0.9429777421184946\n",
      "Performance on Unseen Data:\n",
      "Accuracy: 0.9436666666666667\n",
      "Precision: 0.944487940151616\n",
      "Recall: 0.9436666666666667\n",
      "F1-Score: 0.9424029494507786\n",
      "Confusion Matrix:\n",
      "[[1529   86    0  102    2  290]\n",
      " [  21 1993    0    0    0   42]\n",
      " [   3    0 2002    0    0    0]\n",
      " [   0    0    0 2004    0    0]\n",
      " [   6    0    0    0 1959    0]\n",
      " [ 111   13    0    0    0 1837]]\n",
      "0.9785324074074074\n",
      "0.9441875\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics for each fold\n",
    "for i in range(10):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[i]}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1-Score: {f1_scores[i]}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrices[i]}\\n\")\n",
    "\n",
    "print(f\"Average Training Accuracy: {sum(train_accuracies) / 10}\")\n",
    "print(f\"Average Testing Accuracy: {sum(test_accuracies) / 10}\")\n",
    "print(f\"Average Precision: {sum(precisions) / 10}\")\n",
    "print(f\"Average recall: {sum(recalls) / 10}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / 10}\")\n",
    "\n",
    "# Print the performance on the unseen data\n",
    "print(\"Performance on Unseen Data:\")\n",
    "print(f\"Accuracy: {unseen_accuracy}\")\n",
    "print(f\"Precision: {unseen_precision}\")\n",
    "print(f\"Recall: {unseen_recall}\")\n",
    "print(f\"F1-Score: {unseen_f1}\")\n",
    "print(f\"Confusion Matrix:\\n{unseen_conf_matrix}\")\n",
    "print(sum(train_accuracies) / 10)\n",
    "print(sum(test_accuracies) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605dcc42-926e-43fa-9fcc-8a878e042bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted Feature Importance (WFI):\n",
      "                 Feature  Importance\n",
      "0     Count of Source IP    0.275738\n",
      "5               Protocol    0.259403\n",
      "1             Port Count    0.173852\n",
      "6   Average Packet Count    0.082110\n",
      "7     Average Byte Count    0.059864\n",
      "10     Duration per Flow    0.042722\n",
      "3      Packet Count Diff    0.040246\n",
      "4      Lookup Count Diff    0.029854\n",
      "8         Packet Std Dev    0.022699\n",
      "2       Pair Count Ratio    0.007773\n",
      "9           Byte Std Dev    0.005739\n"
     ]
    }
   ],
   "source": [
    "# Calculate Weighted Feature Importance (WFI)\n",
    "feature_importances = rnd.feature_importances_\n",
    "wfi = feature_importances / feature_importances.sum()\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': wfi\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nWeighted Feature Importance (WFI):\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed82d58-9aec-40ce-b2a8-e01056ff8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('rf_multi.pkl', 'wb') as file:\n",
    "#     pickle.dump(rnd, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
