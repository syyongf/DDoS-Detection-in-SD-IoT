{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b3d806-4ff7-4a58-822a-487ec28c0072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "df = pd.read_csv('research_traffic.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d5044e-30e4-4889-b8b5-cf9446f8051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count_of_Source_IP        int64\n",
      "Port_Count                int64\n",
      "Pair_Count_Ratio        float64\n",
      "Packet_Count_Diff         int64\n",
      "Lookup_Count_Diff         int64\n",
      "Protocol                  int64\n",
      "Average_Packet_Count    float64\n",
      "Average_Byte_Count      float64\n",
      "Packet_Std_Dev          float64\n",
      "Byte_Std_Dev            float64\n",
      "Duration_per_Flow       float64\n",
      "Label                     int64\n",
      "dtype: object\n",
      "70000\n",
      "70000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_of_Source_IP</th>\n",
       "      <th>Port_Count</th>\n",
       "      <th>Pair_Count_Ratio</th>\n",
       "      <th>Packet_Count_Diff</th>\n",
       "      <th>Lookup_Count_Diff</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Average_Packet_Count</th>\n",
       "      <th>Average_Byte_Count</th>\n",
       "      <th>Packet_Std_Dev</th>\n",
       "      <th>Byte_Std_Dev</th>\n",
       "      <th>Duration_per_Flow</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436913</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>145637.6667</td>\n",
       "      <td>3.567915e+09</td>\n",
       "      <td>24719.5</td>\n",
       "      <td>5.339086e+09</td>\n",
       "      <td>1.258000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436912</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>145637.3333</td>\n",
       "      <td>3.567915e+09</td>\n",
       "      <td>24721.0</td>\n",
       "      <td>5.339086e+09</td>\n",
       "      <td>1.254000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1006277</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>335425.6667</td>\n",
       "      <td>8.291520e+09</td>\n",
       "      <td>61289.5</td>\n",
       "      <td>1.240812e+10</td>\n",
       "      <td>2.587333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1006280</td>\n",
       "      <td>6</td>\n",
       "      <td>335426.0000</td>\n",
       "      <td>8.291520e+09</td>\n",
       "      <td>61288.0</td>\n",
       "      <td>1.240812e+10</td>\n",
       "      <td>2.592000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1605562</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>535187.3333</td>\n",
       "      <td>1.321503e+10</td>\n",
       "      <td>97006.0</td>\n",
       "      <td>1.977597e+10</td>\n",
       "      <td>3.926000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count_of_Source_IP  Port_Count  Pair_Count_Ratio  Packet_Count_Diff  \\\n",
       "0                   2           2               1.0             436913   \n",
       "1                   2           2               1.0             436912   \n",
       "2                   2           2               1.0            1006277   \n",
       "3                   2           2               0.0                  1   \n",
       "4                   2           2               1.0            1605562   \n",
       "\n",
       "   Lookup_Count_Diff  Protocol  Average_Packet_Count  Average_Byte_Count  \\\n",
       "0                  1         6           145637.6667        3.567915e+09   \n",
       "1                  1         6           145637.3333        3.567915e+09   \n",
       "2                  1         6           335425.6667        8.291520e+09   \n",
       "3            1006280         6           335426.0000        8.291520e+09   \n",
       "4                  6         6           535187.3333        1.321503e+10   \n",
       "\n",
       "   Packet_Std_Dev  Byte_Std_Dev  Duration_per_Flow  Label  \n",
       "0         24719.5  5.339086e+09           1.258000      0  \n",
       "1         24721.0  5.339086e+09           1.254000      0  \n",
       "2         61289.5  1.240812e+10           2.587333      0  \n",
       "3         61288.0  1.240812e+10           2.592000      0  \n",
       "4         97006.0  1.977597e+10           3.926000      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df['Label'].value_counts()[1])\n",
    "print(df['Label'].value_counts()[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb6bce6-e849-43c6-b3c9-d456368ac9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obj_cols=df_dt.dtypes[df_dt.dtypes == \"object\"].index.values.tolist()\n",
    "# print(obj_cols)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# #Encode labels of multiple columns at once\n",
    "\n",
    "# df_dt[obj_cols] = df_dt[obj_cols].astype(str)\n",
    "# df_dt[obj_cols] = df_dt[obj_cols].apply(LabelEncoder().fit_transform)\n",
    "# #\n",
    "# # Print head\n",
    "# #\n",
    "# print(df_dt.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa701bd-bb1b-4e89-86c2-3c623d9b981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset normalized using MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score, make_scorer\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "y = df.Label\n",
    "X = df.drop(['Label'],axis=1)\n",
    "\n",
    "# Normalize the dataset using MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "X = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "print(\"Dataset normalized using MinMaxScaler.\")\n",
    "\n",
    "# # Scale the dataset using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "X_train_cv, X_unseen_test, y_train_cv, y_unseen_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c760dda-b4ee-4dd7-90ba-dd0518bafd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "start = datetime.now()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_cv):\n",
    "    X_train, X_test = X_train_cv.iloc[train_index], X_train_cv.iloc[test_index]\n",
    "    y_train, y_test = y_train_cv.iloc[train_index], y_train_cv.iloc[test_index]\n",
    "    \n",
    "    # Train the dt classifier\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test fold\n",
    "    y_pred_test = dt.predict(X_test)\n",
    "    y_pred_train = dt.predict(X_train)\n",
    "    \n",
    "    # Calculate metrics for the test fold\n",
    "    train_accuracies.append(accuracy_score(y_train, y_pred_train))\n",
    "    test_accuracies.append(accuracy_score(y_test, y_pred_test))\n",
    "    precisions.append(precision_score(y_test, y_pred_test))\n",
    "    recalls.append(recall_score(y_test, y_pred_test))\n",
    "    f1_scores.append(f1_score(y_test, y_pred_test))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Test the final model on unseen data\n",
    "y_unseen_pred = dt.predict(X_unseen_test)\n",
    "unseen_accuracy = accuracy_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_precision = precision_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_recall = recall_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_f1 = f1_score(y_unseen_test, y_unseen_pred)\n",
    "unseen_conf_matrix = confusion_matrix(y_unseen_test, y_unseen_pred)\n",
    "end = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3275ce-c222-4d1e-85bf-08bc9c8b7363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix:\n",
      "[[5491.6  122.3]\n",
      " [ 122.3 5463.8]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average confusion matrix\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an array to store the sum of confusion matrices\n",
    "confusion_matrix_sum = np.zeros((2, 2))  # Adjust the size if multi-class classification\n",
    "\n",
    "# During the cross-validation loop, confusion matrices were already calculated\n",
    "# Here, we'll sum up those matrices (assumes `confusion_matrices` contains all fold matrices)\n",
    "for cm in confusion_matrices:\n",
    "    confusion_matrix_sum += cm\n",
    "\n",
    "# Compute the average confusion matrix\n",
    "average_conf_matrix = confusion_matrix_sum / 10\n",
    "\n",
    "# Display the average confusion matrix\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(average_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29e3b50-cb72-4f68-9fa7-a0679b9cfcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training Accuracy: 0.9999603174603174\n",
      "Testing Accuracy: 0.9775892857142857\n",
      "Precision: 0.9778413152251608\n",
      "Recall: 0.9773173781032327\n",
      "F1-Score: 0.9775792764627066\n",
      "Confusion Matrix:\n",
      "[[5477  124]\n",
      " [ 127 5472]]\n",
      "\n",
      "Fold 2:\n",
      "Training Accuracy: 0.9999702380952381\n",
      "Testing Accuracy: 0.9783035714285714\n",
      "Precision: 0.9784676116992643\n",
      "Recall: 0.9779411764705882\n",
      "F1-Score: 0.9782043232576912\n",
      "Confusion Matrix:\n",
      "[[5504  120]\n",
      " [ 123 5453]]\n",
      "\n",
      "Fold 3:\n",
      "Training Accuracy: 0.9999603174603174\n",
      "Testing Accuracy: 0.9783928571428572\n",
      "Precision: 0.9795918367346939\n",
      "Recall: 0.9775101823977334\n",
      "F1-Score: 0.9785499024995569\n",
      "Confusion Matrix:\n",
      "[[5438  115]\n",
      " [ 127 5520]]\n",
      "\n",
      "Fold 4:\n",
      "Training Accuracy: 0.9999404761904762\n",
      "Testing Accuracy: 0.9789285714285715\n",
      "Precision: 0.9793478260869565\n",
      "Recall: 0.9779305354558611\n",
      "F1-Score: 0.9786386676321506\n",
      "Confusion Matrix:\n",
      "[[5558  114]\n",
      " [ 122 5406]]\n",
      "\n",
      "Fold 5:\n",
      "Training Accuracy: 0.9999404761904762\n",
      "Testing Accuracy: 0.9802678571428571\n",
      "Precision: 0.9796682718031032\n",
      "Recall: 0.9808928571428571\n",
      "F1-Score: 0.980280182029089\n",
      "Confusion Matrix:\n",
      "[[5486  114]\n",
      " [ 107 5493]]\n",
      "\n",
      "Fold 6:\n",
      "Training Accuracy: 0.9999603174603174\n",
      "Testing Accuracy: 0.9785714285714285\n",
      "Precision: 0.9803745048613611\n",
      "Recall: 0.976506456241033\n",
      "F1-Score: 0.9784366576819407\n",
      "Confusion Matrix:\n",
      "[[5515  109]\n",
      " [ 131 5445]]\n",
      "\n",
      "Fold 7:\n",
      "Training Accuracy: 0.9999503968253968\n",
      "Testing Accuracy: 0.9755357142857143\n",
      "Precision: 0.9774637810767305\n",
      "Recall: 0.9736326385177267\n",
      "F1-Score: 0.9755444484112817\n",
      "Confusion Matrix:\n",
      "[[5461  126]\n",
      " [ 148 5465]]\n",
      "\n",
      "Fold 8:\n",
      "Training Accuracy: 0.9999404761904762\n",
      "Testing Accuracy: 0.9805357142857143\n",
      "Precision: 0.9789548778312823\n",
      "Recall: 0.9821077115763106\n",
      "F1-Score: 0.9805287602715256\n",
      "Confusion Matrix:\n",
      "[[5493  118]\n",
      " [ 100 5489]]\n",
      "\n",
      "Fold 9:\n",
      "Training Accuracy: 0.9999503968253968\n",
      "Testing Accuracy: 0.9766071428571429\n",
      "Precision: 0.9761092150170648\n",
      "Recall: 0.9768110731619629\n",
      "F1-Score: 0.9764600179694519\n",
      "Confusion Matrix:\n",
      "[[5504  133]\n",
      " [ 129 5434]]\n",
      "\n",
      "Fold 10:\n",
      "Training Accuracy: 0.9999404761904762\n",
      "Testing Accuracy: 0.976875\n",
      "Precision: 0.973266797362324\n",
      "Recall: 0.9804308797127469\n",
      "F1-Score: 0.9768357034254539\n",
      "Confusion Matrix:\n",
      "[[5480  150]\n",
      " [ 109 5461]]\n",
      "\n",
      "Average Training Accuracy: 0.9999513888888888\n",
      "Average Testing Accuracy: 0.9781607142857143\n",
      "Average Precision: 0.9781086037697942\n",
      "Average recall: 0.9781080888780054\n",
      "Average F1 Score: 0.9781057939640847\n",
      "Performance on Unseen Data:\n",
      "Accuracy: 0.9785357142857143\n",
      "Precision: 0.978442182640656\n",
      "Recall: 0.9790649975245774\n",
      "F1-Score: 0.9787534910029342\n",
      "Confusion Matrix:\n",
      "[[13556   305]\n",
      " [  296 13843]]\n",
      "excution time:  0:00:04.388319\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics for each fold\n",
    "for i in range(10):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[i]}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1-Score: {f1_scores[i]}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrices[i]}\\n\")\n",
    "\n",
    "print(f\"Average Training Accuracy: {sum(train_accuracies) / 10}\")\n",
    "print(f\"Average Testing Accuracy: {sum(test_accuracies) / 10}\")\n",
    "print(f\"Average Precision: {sum(precisions) / 10}\")\n",
    "print(f\"Average recall: {sum(recalls) / 10}\")\n",
    "print(f\"Average F1 Score: {sum(f1_scores) / 10}\")\n",
    "\n",
    "# Print the performance on the unseen data\n",
    "print(\"Performance on Unseen Data:\")\n",
    "print(f\"Accuracy: {unseen_accuracy}\")\n",
    "print(f\"Precision: {unseen_precision}\")\n",
    "print(f\"Recall: {unseen_recall}\")\n",
    "print(f\"F1-Score: {unseen_f1}\")\n",
    "print(f\"Confusion Matrix:\\n{unseen_conf_matrix}\")\n",
    "print(\"excution time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605dcc42-926e-43fa-9fcc-8a878e042bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted Feature Importance (WFI):\n",
      "                 Feature  Importance\n",
      "0     Count_of_Source_IP    0.863198\n",
      "10     Duration_per_Flow    0.060893\n",
      "4      Lookup_Count_Diff    0.017235\n",
      "9           Byte_Std_Dev    0.012269\n",
      "6   Average_Packet_Count    0.010279\n",
      "7     Average_Byte_Count    0.009389\n",
      "1             Port_Count    0.008984\n",
      "3      Packet_Count_Diff    0.008755\n",
      "2       Pair_Count_Ratio    0.003760\n",
      "8         Packet_Std_Dev    0.003704\n",
      "5               Protocol    0.001535\n"
     ]
    }
   ],
   "source": [
    "# Calculate Weighted Feature Importance (WFI)\n",
    "feature_importances = dt.feature_importances_\n",
    "wfi = feature_importances / feature_importances.sum()\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': wfi\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nWeighted Feature Importance (WFI):\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ffc0a4-e2db-4fa6-accf-94c8deef848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('dt_binary.pkl', 'wb') as file:\n",
    "#     pickle.dump(dt, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
